{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11206aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import requests\n",
    "import regex as re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ad679f",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magic():\n",
    "    response = get_data()  # This makes the external call to the internet. This is why we want to keep it separate\n",
    "    data = parse_html(response.text)  # This function can be unittest. It extracts data from response\n",
    "    save_data(data)  # Possibly, working with files, therefore might need to extract to separate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83b46589",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_SOURCE = \"https://www.goodreads.com/\"\n",
    "URL_START = \"https://www.goodreads.com/list/tag/\"\n",
    "BOOK_CATEGORIES = [\n",
    "    \"romance\",\n",
    "    \"fiction\",\n",
    "    \"young-adult\",\n",
    "    \"fantasy\",\n",
    "    \"science-fiction\",\n",
    "    \"non-fiction\",\n",
    "    \"children\",\n",
    "    \"history\",\n",
    "    \"covers\",\n",
    "    \"mystery\",\n",
    "    \"horror\",\n",
    "    \"best\",\n",
    "    \"historical-fiction\",\n",
    "    \"gay\",\n",
    "    \"paranormal\",\n",
    "    \"love\",\n",
    "    \"titles\",\n",
    "    \"contemporary\",\n",
    "    \"middle-grade\",\n",
    "    \"historical-romance\",\n",
    "    \"biography\",\n",
    "    \"thriller\",\n",
    "    \"series\",\n",
    "    \"women\",\n",
    "    \"nonfiction\",\n",
    "    \"classics\",\n",
    "    \"lgbt\",\n",
    "    \"graphic-novels\",\n",
    "    \"memoir\",\n",
    "    \"queer\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e362f4",
   "metadata": {},
   "source": [
    "Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "042b723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_body(url: str):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print (\"http error:\",errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print (\"conection error:\",errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print (\"timeout error:\",errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print (\"other error:\",err)\n",
    "        \n",
    "    if response.status_code == 200:\n",
    "        page = bs.BeautifulSoup(response.text)\n",
    "        return page.body\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def clean_text(s: str):\n",
    "    s = re.sub(r'[\\n\\t]', ' ', s)\n",
    "    s = s.strip()\n",
    "    s = ' '.join(s.split())\n",
    "    return s\n",
    "\n",
    "    \n",
    "def get_category_urls(input_url: str = URL_START, top_n:int = 1) -> dict:\n",
    "    category_urls = {}\n",
    "    for category in BOOK_CATEGORIES:\n",
    "        page_body = get_page_body(input_url + category)\n",
    "        if page_body:\n",
    "            link = page_body.find(\"div\",{\"class\": \"listImgs\"}).find(\"a\")['href']\n",
    "            links = [\"https://www.goodreads.com/\" + link + f\"?page={i}\" for i in range(1,top_n+1)]\n",
    "            category_urls[category] = links\n",
    "    return category_urls\n",
    "\n",
    "\n",
    "def get_links(body):\n",
    "    hrefs = body.find(\"div\",{\"class\": \"listImgs\"}).find(\"a\")['href']\n",
    "    links = [\"https://www.goodreads.com/\" + hrefs + f\"?page={i}\" for i in range(1, top_n+1)]\n",
    "\n",
    "def get_category_urls(input_url: str = URL_START, top_n:int = 1) -> dict:\n",
    "    category_urls = {}\n",
    "    {category:get_links_for_body(body) for category in BOOK_CATEGORIES}\n",
    "    for category in BOOK_CATEGORIES:\n",
    "        page_body = get_page_body(input_url + category)\n",
    "        if page_body:\n",
    "            link = page_body.find(\"div\",{\"class\": \"listImgs\"}).find(\"a\")['href']\n",
    "            links = [f\"https://www.goodreads.com/{link}?page={i}\" for i in range(1, top_n+1)]\n",
    "            category_urls[category] = links\n",
    "    return category_urls\n",
    "\n",
    "\n",
    "def get_separate_book_urls(url: str):\n",
    "    page_body = get_page_body(url)\n",
    "    parse_for_urls(response.text)\n",
    "    return urls\n",
    "\n",
    "\n",
    "def get_text(x):\n",
    "    return clean_text(getattr(x, \"text\", \"\"))\n",
    "\n",
    "\n",
    "def get_book_info(page_body, book_category: str):\n",
    "    book_info = {}\n",
    "    book_info[\"category\"] = book_category\n",
    "\n",
    "    patterns = [\n",
    "        [\"title\", \"h1\", \"id\", \"bookTitle\"],\n",
    "        ['author', 'span', \"itemprop\", 'name'],\n",
    "    ]\n",
    "\n",
    "    for key, el, prop, prop_value in patterns:\n",
    "        book_info[key] = get_text(page_body.find(el, **{prop:prop_value}))\n",
    "\n",
    "\n",
    "    book_info[\"title\"] = get_text(page_body.find(\"h1\", id = \"bookTitle\"))\n",
    "    book_info[\"author\"] = get_text(page_body.find(\"span\", itemprop=\"name\"))\n",
    "    book_info[\"description\"] = get_text(page_body.find(\"div\", id=\"description\"))\n",
    "    book_info[\"rating\"] =  get_text(page_body.find(\"span\", itemprop=\"ratingValue\"))\n",
    "    book_info[\"number_of_pages\"] = get_text(page_body.find(\"span\", itemprop=\"numberOfPages\"))\n",
    "    book_info[\"url\"] = url\n",
    "    return book_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9ff0c7",
   "metadata": {},
   "source": [
    "Main scraping script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "653eb0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_db = pd.DataFrame()\n",
    "category_urls = get_category_urls()\n",
    "\n",
    "for category in category_urls.keys():\n",
    "    if category_urls[category]:\n",
    "        for page_url in category_urls[category]:\n",
    "            books_urls_list = get_separate_book_urls(page_url)\n",
    "            if books_urls_list:\n",
    "                for book_url in books_urls_list:\n",
    "                    book_info = get_book_info(book_url, category)\n",
    "                    if book_info:\n",
    "                        books_db = books_db.append(book_info, ignore_index=True)\n",
    "books_db.to_parquet(\"books_info.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e4b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_db = pd.DataFrame()\n",
    "category_urls = get_category_urls()\n",
    "\n",
    "for category in category_urls.keys():\n",
    "    url = category_urls[category]\n",
    "    if not url:\n",
    "        continue\n",
    "\n",
    "    for page_url in url:\n",
    "        books_urls_list = get_separate_book_urls(page_url)\n",
    "        if not books_urls_list:\n",
    "            continue\n",
    "\n",
    "        for book_url in books_urls_list:\n",
    "            book_info = get_book_info(book_url, category)\n",
    "            if book_info:\n",
    "                books_db = books_db.append(book_info, ignore_index=True)\n",
    "books_db.to_parquet(\"books_info.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b26d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "page_urls = handle_category()\n",
    "book_urls = get_book_urls(page_urls)\n",
    "books_data = get_books_data(book_urls)\n",
    "\n",
    "def get_book_urls():\n",
    "    # Get response\n",
    "    # Parse response\n",
    "    # Return data\n",
    "\n",
    "def get_books_data():\n",
    "    # Get response\n",
    "    # Parse response\n",
    "    # Return data\n",
    "\n",
    "books_db = pd.DataFrame(books_data)\n",
    "books_db.to_parquet(\"books_info.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"books_info.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f1e2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
